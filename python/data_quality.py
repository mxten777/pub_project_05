#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Data Quality Report Generator
ë°ì´í„° í’ˆì§ˆ(ì •í•©ì„±) ê²€ì¦ ë° ë¦¬í¬íŠ¸ ìƒì„±

Usage:
    python data_quality.py --source mock
    python data_quality.py --source real --input collected_bids.json
    python data_quality.py --source mock --count 200 --sample 5
    python data_quality.py --source real --input collected_bids.json --run-id demo001
"""

import json
import argparse
from datetime import datetime
from typing import List, Dict, Any, Optional
import os
import sys

# Mock ë°ì´í„° ìƒì„± í•¨ìˆ˜ (collect_bids.pyì™€ ìœ ì‚¬)
def generate_mock_data(count: int = 20) -> List[Dict[str, Any]]:
    """Mock ì…ì°° ë°ì´í„° ìƒì„±"""
    agencies = ['ì„œìš¸íŠ¹ë³„ì‹œì²­', 'ê²½ê¸°ë„ì²­', 'ì¸ì²œê´‘ì—­ì‹œì²­', 'ë¶€ì‚°ê´‘ì—­ì‹œì²­', 'ëŒ€ì „ê´‘ì—­ì‹œì²­']
    categories = ['ì†Œí”„íŠ¸ì›¨ì–´', 'ê±´ì„¤', 'ìš©ì—­', 'ë¬¼í’ˆ', 'ê¸°íƒ€']
    regions = ['ì„œìš¸', 'ê²½ê¸°', 'ì¸ì²œ', 'ë¶€ì‚°', 'ëŒ€ì „']
    statuses = ['active', 'closed', 'modified']
    
    data = []
    base_date = datetime(2024, 12, 1)
    
    for i in range(count):
        # ì˜ë„ì ìœ¼ë¡œ ì¼ë¶€ ë ˆì½”ë“œì— ë¬¸ì œ ì‚½ì… (í…ŒìŠ¤íŠ¸ìš©)
        record = {
            'id': str(i + 1),
            'title': f'2024ë…„ ìŠ¤ë§ˆíŠ¸ì‹œí‹° í†µí•©í”Œë«í¼ êµ¬ì¶•ì‚¬ì—… {i+1}',
            'agency': agencies[i % len(agencies)],
            'category': categories[i % len(categories)],
            'region': regions[i % len(regions)],
            'budget': 500000000 + (i * 10000000),
            'deadline': '2024-12-31T23:59:59',
            'status': statuses[i % len(statuses)],
            'createdAt': base_date.isoformat(),
        }
        
        # ì˜ë„ì  í’ˆì§ˆ ë¬¸ì œ ì‚½ì… (ì¼ë¶€ ë ˆì½”ë“œë§Œ)
        if i == 5:
            record['title'] = ''  # ë¹ˆ ì œëª©
        if i == 7:
            record['budget'] = -1000  # ìŒìˆ˜ ì˜ˆì‚°
        if i == 9:
            record['deadline'] = 'invalid-date'  # ì˜ëª»ëœ ë‚ ì§œ
        if i == 11:
            record['status'] = 'unknown'  # ì˜ëª»ëœ ìƒíƒœ
        if i == 13:
            del record['agency']  # í•„ë“œ ëˆ„ë½
        if i == 15:
            record['id'] = '5'  # ì¤‘ë³µ ID
        if i == 17:
            record['title'] = 'abc'  # ë„ˆë¬´ ì§§ì€ ì œëª©
        if i == 18:
            record['updatedAt'] = datetime.now().isoformat()  # ê°±ì‹  ì‹œê°„ ì¶”ê°€
        
        data.append(record)
    
    return data


class DataQualityChecker:
    """ë°ì´í„° í’ˆì§ˆ ê²€ì¦ê¸°"""
    
    def __init__(self, records: List[Dict[str, Any]]):
        self.records = records
        self.total_count = len(records)
        self.results = {
            'total_records': self.total_count,
            'valid_records': 0,
            'field_stats': {},
            'type_errors': {},
            'duplicates': {},
            'anomalies': {},
            'summary': {},
            'judgment': ''
        }
    
    def check_all(self) -> Dict[str, Any]:
        """ì „ì²´ í’ˆì§ˆ ê²€ì¦ ì‹¤í–‰"""
        print("ğŸ“Š ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì‹œì‘...")
        
        self.check_missing_fields()
        self.check_type_errors()
        self.check_duplicates()
        self.check_anomalies()
        self.calculate_scores()
        self.make_judgment()
        
        print("âœ… ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì™„ë£Œ")
        return self.results
    
    def check_missing_fields(self):
        """í•„ìˆ˜ í•„ë“œ ëˆ„ë½ ê²€ì¦"""
        required_fields = ['id', 'title', 'agency', 'category', 'region', 
                          'budget', 'deadline', 'status', 'createdAt']
        
        field_stats = {}
        records_with_missing = 0
        
        for field in required_fields:
            missing_count = 0
            for record in self.records:
                value = record.get(field)
                if value is None or value == '':
                    missing_count += 1
            
            missing_rate = (missing_count / self.total_count * 100) if self.total_count > 0 else 0
            field_stats[field] = {
                'missing_count': missing_count,
                'missing_rate': round(missing_rate, 2)
            }
        
        # í•„ìˆ˜ í•„ë“œê°€ í•˜ë‚˜ë¼ë„ ëˆ„ë½ëœ ë ˆì½”ë“œ ì¹´ìš´íŠ¸
        for record in self.records:
            has_missing = any(
                record.get(field) is None or record.get(field) == ''
                for field in required_fields
            )
            if has_missing:
                records_with_missing += 1
        
        self.results['field_stats'] = field_stats
        self.results['records_with_missing_rate'] = round(
            (records_with_missing / self.total_count * 100), 2
        ) if self.total_count > 0 else 0
    
    def check_type_errors(self):
        """íƒ€ì…/íŒŒì‹± ì˜¤ë¥˜ ê²€ì¦"""
        budget_errors = 0
        deadline_errors = 0
        status_errors = 0
        allowed_statuses = ['active', 'closed', 'modified']
        
        for record in self.records:
            # Budget ìˆ«ì ê²€ì¦
            try:
                budget = record.get('budget')
                if budget is not None:
                    float(budget)
            except (ValueError, TypeError):
                budget_errors += 1
            
            # Deadline ë‚ ì§œ ê²€ì¦
            deadline = record.get('deadline')
            if deadline:
                try:
                    # ISO í˜•ì‹ ë˜ëŠ” YYYY-MM-DD í˜•ì‹ íŒŒì‹± ì‹œë„
                    if 'T' in deadline:
                        datetime.fromisoformat(deadline.replace('Z', '+00:00'))
                    else:
                        datetime.strptime(deadline, '%Y-%m-%d')
                except (ValueError, AttributeError):
                    deadline_errors += 1
            
            # Status ê°’ ê²€ì¦
            status = record.get('status')
            if status and status not in allowed_statuses:
                status_errors += 1
        
        self.results['type_errors'] = {
            'budget': {
                'error_count': budget_errors,
                'error_rate': round((budget_errors / self.total_count * 100), 2)
            },
            'deadline': {
                'error_count': deadline_errors,
                'error_rate': round((deadline_errors / self.total_count * 100), 2)
            },
            'status': {
                'error_count': status_errors,
                'error_rate': round((status_errors / self.total_count * 100), 2)
            }
        }
    
    def check_duplicates(self):
        """ì¤‘ë³µ ID ê²€ì¦ (ìµœì‹  ë ˆì½”ë“œë§Œ ìœ íš¨ë¡œ íŒë‹¨)"""
        id_map = {}
        
        for record in self.records:
            record_id = record.get('id')
            if not record_id:
                continue
            
            if record_id not in id_map:
                id_map[record_id] = []
            id_map[record_id].append(record)
        
        duplicates = {k: v for k, v in id_map.items() if len(v) > 1}
        duplicate_count = sum(len(v) - 1 for v in duplicates.values())
        
        # ìµœì‹  ë ˆì½”ë“œë§Œ ìœ íš¨ë¡œ ì²˜ë¦¬
        valid_count = self.total_count - duplicate_count
        
        self.results['duplicates'] = {
            'duplicate_ids': list(duplicates.keys()),
            'duplicate_count': duplicate_count,
            'duplicate_rate': round((duplicate_count / self.total_count * 100), 2) if self.total_count > 0 else 0
        }
        self.results['valid_records'] = valid_count
    
    def check_anomalies(self):
        """ê°’ ë²”ìœ„/ì´ìƒì¹˜ ê²€ì¦"""
        negative_budget_count = 0
        short_title_count = 0
        long_title_count = 0
        past_deadline_count = 0
        now = datetime.now()
        
        for record in self.records:
            # Budget <= 0
            budget = record.get('budget')
            if budget is not None:
                try:
                    if float(budget) <= 0:
                        negative_budget_count += 1
                except (ValueError, TypeError):
                    pass
            
            # Title ê¸¸ì´
            title = record.get('title', '')
            if len(title) < 5 and len(title) > 0:
                short_title_count += 1
            elif len(title) > 200:
                long_title_count += 1
            
            # Deadlineì´ ê³¼ê±°ì¸ì§€ í™•ì¸
            deadline = record.get('deadline')
            if deadline:
                try:
                    if 'T' in deadline:
                        deadline_dt = datetime.fromisoformat(deadline.replace('Z', '+00:00'))
                    else:
                        deadline_dt = datetime.strptime(deadline, '%Y-%m-%d')
                    
                    if deadline_dt < now:
                        past_deadline_count += 1
                except (ValueError, AttributeError):
                    pass
        
        self.results['anomalies'] = {
            'negative_budget': {
                'count': negative_budget_count,
                'rate': round((negative_budget_count / self.total_count * 100), 2)
            },
            'short_title': {
                'count': short_title_count,
                'rate': round((short_title_count / self.total_count * 100), 2)
            },
            'long_title': {
                'count': long_title_count,
                'rate': round((long_title_count / self.total_count * 100), 2)
            },
            'past_deadline': {
                'count': past_deadline_count,
                'rate': round((past_deadline_count / self.total_count * 100), 2)
            }
        }
    
    def calculate_scores(self):
        """ì ìˆ˜ ê³„ì‚°"""
        # ì™„ì „ì„± ì ìˆ˜ (100 - ê°€ì¤‘ ëˆ„ë½ë¥ )
        critical_fields = ['id', 'title', 'agency']
        critical_missing_rate = sum(
            self.results['field_stats'][f]['missing_rate'] 
            for f in critical_fields
        ) / len(critical_fields)
        
        all_missing_rate = sum(
            stat['missing_rate'] 
            for stat in self.results['field_stats'].values()
        ) / len(self.results['field_stats'])
        
        completeness_score = max(0, 100 - (critical_missing_rate * 2 + all_missing_rate) / 3)
        
        # íŒŒì‹± ê±´ì „ì„± ì ìˆ˜ (100 - ê°€ì¤‘ ì˜¤ë¥˜ìœ¨)
        type_error_rate = sum(
            err['error_rate'] 
            for err in self.results['type_errors'].values()
        ) / len(self.results['type_errors'])
        
        parsing_score = max(0, 100 - type_error_rate * 1.5)
        
        self.results['summary'] = {
            'completeness_score': round(completeness_score, 2),
            'parsing_score': round(parsing_score, 2),
            'duplicate_rate': self.results['duplicates']['duplicate_rate'],
            'critical_missing_rate': round(critical_missing_rate, 2),
            'type_error_rate': round(type_error_rate, 2)
        }
    
    def make_judgment(self):
        """ìµœì¢… íŒì •"""
        summary = self.results['summary']
        
        # PASS ê¸°ì¤€
        pass_criteria = [
            summary['critical_missing_rate'] < 1,  # í•µì‹¬ í•„ë“œ ëˆ„ë½ë¥  < 1%
            self.results['type_errors']['deadline']['error_rate'] < 1,  # deadline íŒŒì‹± < 1%
            self.results['type_errors']['budget']['error_rate'] < 2,  # budget íŒŒì‹± < 2%
            summary['duplicate_rate'] < 3  # ì¤‘ë³µë¥  < 3%
        ]
        
        passed_count = sum(pass_criteria)
        
        if passed_count == 4:
            judgment = 'PASS'
            reason = 'ëª¨ë“  í’ˆì§ˆ ê¸°ì¤€ ì¶©ì¡±'
        elif passed_count >= 2:
            judgment = 'CONDITIONAL PASS'
            reason = f'{4 - passed_count}ê°œ ê¸°ì¤€ ë¯¸ì¶©ì¡±, ë°ì´í„° ì •ì œ í›„ ì‚¬ìš© ê°€ëŠ¥'
        else:
            judgment = 'FAIL'
            reason = f'{4 - passed_count}ê°œ ê¸°ì¤€ ë¯¸ì¶©ì¡±, ë°ì´í„° ì •ì œ í•„ìˆ˜'
        
        # ì¹˜ëª…ì  ë¬¸ì œ ì²´í¬
        if summary['critical_missing_rate'] > 10:
            judgment = 'FAIL'
            reason = 'í•µì‹¬ í•„ë“œ(id/title/agency) ëˆ„ë½ë¥ ì´ ë†’ìŒ - ë°ì´í„° ìˆ˜ì§‘ ì¬ì‹¤í–‰ í•„ìš”'
        
        self.results['judgment'] = judgment
        self.results['judgment_reason'] = reason
        self.results['pass_criteria_met'] = f'{passed_count}/4'


def generate_json_report(results: Dict[str, Any], output_path: str):
    """JSON ë¦¬í¬íŠ¸ ìƒì„±"""
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    print(f"ğŸ“„ JSON ë¦¬í¬íŠ¸ ìƒì„±: {output_path}")


def generate_markdown_report(results: Dict[str, Any], output_path: str, sample_records: Optional[List[Dict]] = None):
    """Markdown ë¦¬í¬íŠ¸ ìƒì„±"""
    summary = results['summary']
    
    md_content = f"""# ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸ (Data Quality Report)

**ìƒì„±ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ“Š ìš”ì•½ (Executive Summary)

- **ì´ ë ˆì½”ë“œ ìˆ˜**: {results['total_records']:,}ê±´
- **ìœ íš¨ ë ˆì½”ë“œ ìˆ˜**: {results['valid_records']:,}ê±´ (ì¤‘ë³µ ì œì™¸)
- **ìµœì¢… íŒì •**: **{results['judgment']}** ({results['pass_criteria_met']} ê¸°ì¤€ í†µê³¼)
- **íŒì • ê·¼ê±°**: {results['judgment_reason']}

### ì£¼ìš” í’ˆì§ˆ ì§€í‘œ
- ì™„ì „ì„± ì ìˆ˜: **{summary['completeness_score']:.2f}/100**
- íŒŒì‹± ê±´ì „ì„± ì ìˆ˜: **{summary['parsing_score']:.2f}/100**
- ì¤‘ë³µë¥ : **{summary['duplicate_rate']:.2f}%**
- í•µì‹¬ í•„ë“œ ëˆ„ë½ë¥ : **{summary['critical_missing_rate']:.2f}%**
---

## âœ… PASS ê¸°ì¤€í‘œ (Quality Criteria)

| í•­ëª© | ê¸°ì¤€ | í˜„ì¬ ê°’ | ìƒíƒœ |
|------|------|---------|------|
| í•µì‹¬ í•„ë“œ ëˆ„ë½ë¥  | < 1% | {summary['critical_missing_rate']:.2f}% | {'âœ… PASS' if summary['critical_missing_rate'] < 1 else 'âŒ FAIL'} |
| deadline íŒŒì‹± ì˜¤ë¥˜ìœ¨ | < 1% | {results['type_errors']['deadline']['error_rate']:.2f}% | {'âœ… PASS' if results['type_errors']['deadline']['error_rate'] < 1 else 'âŒ FAIL'} |
| budget íŒŒì‹± ì˜¤ë¥˜ìœ¨ | < 2% | {results['type_errors']['budget']['error_rate']:.2f}% | {'âœ… PASS' if results['type_errors']['budget']['error_rate'] < 2 else 'âŒ FAIL'} |
| ì¤‘ë³µ ë ˆì½”ë“œìœ¨ | < 3% | {summary['duplicate_rate']:.2f}% | {'âœ… PASS' if summary['duplicate_rate'] < 3 else 'âŒ FAIL'} |
---

## ğŸ“‹ í•„ë“œë³„ ëˆ„ë½ë¥ /ì˜¤ë¥˜ìœ¨

### í•„ìˆ˜ í•„ë“œ ëˆ„ë½ í˜„í™©

| í•„ë“œ | ëˆ„ë½ ê±´ìˆ˜ | ëˆ„ë½ë¥  (%) | ìƒíƒœ |
|------|----------|-----------|------|
"""
    
    for field, stats in results['field_stats'].items():
        status = 'âœ…' if stats['missing_rate'] < 1 else 'âš ï¸' if stats['missing_rate'] < 5 else 'âŒ'
        md_content += f"| {field} | {stats['missing_count']} | {stats['missing_rate']:.2f}% | {status} |\n"
    
    md_content += f"""
**í•„ìˆ˜ í•„ë“œ ë¶ˆì™„ì „ ë ˆì½”ë“œ ë¹„ìœ¨**: {results['records_with_missing_rate']:.2f}%

### íƒ€ì…/íŒŒì‹± ì˜¤ë¥˜ í˜„í™©

| í•„ë“œ | ì˜¤ë¥˜ ê±´ìˆ˜ | ì˜¤ë¥˜ìœ¨ (%) | ìƒíƒœ |
|------|----------|-----------|------|
"""
    
    for field, stats in results['type_errors'].items():
        status = 'âœ…' if stats['error_rate'] < 1 else 'âš ï¸' if stats['error_rate'] < 5 else 'âŒ'
        md_content += f"| {field} | {stats['error_count']} | {stats['error_rate']:.2f}% | {status} |\n"
    
    md_content += f"""
---

## ğŸ” ì¤‘ë³µ ë° ì´ìƒì¹˜ ë¶„ì„

### ì¤‘ë³µ ID
- **ì¤‘ë³µ ID ê°œìˆ˜**: {len(results['duplicates']['duplicate_ids'])}ê°œ
- **ì¤‘ë³µ ë ˆì½”ë“œ ìˆ˜**: {results['duplicates']['duplicate_count']}ê±´
- **ì¤‘ë³µë¥ **: {results['duplicates']['duplicate_rate']:.2f}%

"""
    
    if results['duplicates']['duplicate_ids']:
        md_content += f"**ì¤‘ë³µ ID ëª©ë¡**: {', '.join(results['duplicates']['duplicate_ids'][:10])}"
        if len(results['duplicates']['duplicate_ids']) > 10:
            md_content += f" ... (ì™¸ {len(results['duplicates']['duplicate_ids']) - 10}ê°œ)"
        md_content += "\n\n"
    
    md_content += f"""### ì´ìƒì¹˜ ê°ì§€

| í•­ëª© | ê±´ìˆ˜ | ë¹„ìœ¨ (%) | ì„¤ëª… |
|------|------|---------|------|
| ìŒìˆ˜/0ì› ì˜ˆì‚° | {results['anomalies']['negative_budget']['count']} | {results['anomalies']['negative_budget']['rate']:.2f}% | budget <= 0 |
| ë„ˆë¬´ ì§§ì€ ì œëª© | {results['anomalies']['short_title']['count']} | {results['anomalies']['short_title']['rate']:.2f}% | title ê¸¸ì´ < 5 |
| ë„ˆë¬´ ê¸´ ì œëª© | {results['anomalies']['long_title']['count']} | {results['anomalies']['long_title']['rate']:.2f}% | title ê¸¸ì´ > 200 |
| ê³¼ê±° ë§ˆê°ì¼ | {results['anomalies']['past_deadline']['count']} | {results['anomalies']['past_deadline']['rate']:.2f}% | deadline < í˜„ì¬ |

---

## ğŸ’¡ ê¶Œê³  ì‚¬í•­ (Phase 1 ëŒ€ì‘)

"""
    
    recommendations = []
    
    if summary['critical_missing_rate'] > 1:
        recommendations.append("1. **ê¸´ê¸‰**: API ì‘ë‹µ íŒŒì‹± ë¡œì§ ì ê²€ - í•µì‹¬ í•„ë“œ(id/title/agency) ëˆ„ë½ ë°œìƒ")
    
    if results['type_errors']['deadline']['error_rate'] > 1:
        recommendations.append("2. **ê¸´ê¸‰**: deadline í•„ë“œ ë‚ ì§œ í˜•ì‹ í†µì¼ í•„ìš” (ISO 8601 ê¶Œì¥)")
    
    if results['type_errors']['budget']['error_rate'] > 2:
        recommendations.append("3. **ì¤‘ìš”**: budget í•„ë“œ ìˆ«ì ë³€í™˜ ë¡œì§ ê°•í™” í•„ìš”")
    
    if results['duplicates']['duplicate_rate'] > 3:
        recommendations.append("4. **ì¤‘ìš”**: ì¤‘ë³µ ID ì œê±° ë¡œì§ êµ¬í˜„ - updatedAt ê¸°ì¤€ ìµœì‹  ë ˆì½”ë“œë§Œ ìœ ì§€")
    
    if results['anomalies']['negative_budget']['rate'] > 5:
        recommendations.append("5. **ì ê²€**: ìŒìˆ˜/0ì› ì˜ˆì‚° ë°ì´í„° ì›ì¸ ë¶„ì„ - API ì‘ë‹µ ë˜ëŠ” íŒŒì‹± ë¬¸ì œ ê°€ëŠ¥ì„±")
    
    if not recommendations:
        recommendations.append("âœ… í˜„ì¬ ë°ì´í„° í’ˆì§ˆì€ ì–‘í˜¸í•©ë‹ˆë‹¤. Phase 1 ì‹¤ì œ API ì—°ë™ ì‹œ ì§€ì† ëª¨ë‹ˆí„°ë§ í•„ìš”")
    
    for rec in recommendations[:5]:
        md_content += f"{rec}\n"
    
    md_content += f"""
---

## ğŸ¯ ìµœì¢… íŒì •

**íŒì •**: `{results['judgment']}`

**íŒì • ê·¼ê±°**:
- {results['judgment_reason']}
- í†µê³¼ ê¸°ì¤€: {results['pass_criteria_met']} (ëˆ„ë½ë¥ <1%, deadlineíŒŒì‹±<1%, budgetíŒŒì‹±<2%, ì¤‘ë³µë¥ <3%)
"""
    
    if results['judgment'] == 'PASS':
        md_content += "- âœ… í˜„ì¬ ë°ì´í„°ëŠ” Phase 1 ì‹¤ì œ API ì—°ë™ì— ì‚¬ìš© ê°€ëŠ¥í•œ ìˆ˜ì¤€ì…ë‹ˆë‹¤.\n"
    elif results['judgment'] == 'CONDITIONAL PASS':
        md_content += "- âš ï¸ ì¼ë¶€ í’ˆì§ˆ ì´ìŠˆê°€ ìˆìœ¼ë‚˜, ì •ì œ í›„ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤. ìœ„ ê¶Œê³ ì‚¬í•­ì„ ì°¸ê³ í•˜ì„¸ìš”.\n"
    else:
        md_content += "- âŒ ë°ì´í„° í’ˆì§ˆì´ ë‚®ìŠµë‹ˆë‹¤. ë°ì´í„° ìˆ˜ì§‘ ë¡œì§ì„ ì¬ì ê²€í•˜ê³  ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.\n"
    
    # ìƒ˜í”Œ ë°ì´í„° ì¶”ê°€
    if sample_records:
        md_content += "\n---\n\n## ğŸ“¦ ìƒ˜í”Œ ë°ì´í„° (Sample Records)\n\n"
        for i, record in enumerate(sample_records[:5], 1):
            md_content += f"### ìƒ˜í”Œ {i}\n```json\n{json.dumps(record, ensure_ascii=False, indent=2)}\n```\n\n"
    
    md_content += f"""
---

**ë¦¬í¬íŠ¸ ìƒì„± ë„êµ¬**: Data Quality Checker v1.0  
**ìƒì„± ì‹œê°**: {datetime.now().isoformat()}
"""
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(md_content)
    
    print(f"ğŸ“ Markdown ë¦¬í¬íŠ¸ ìƒì„±: {output_path}")


def main():
    parser = argparse.ArgumentParser(description='ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë° ë¦¬í¬íŠ¸ ìƒì„±')
    parser.add_argument('--source', choices=['mock', 'real'], required=True,
                       help='ë°ì´í„° ì†ŒìŠ¤: mock (ìƒ˜í”Œ ìƒì„±) ë˜ëŠ” real (íŒŒì¼ ë¡œë“œ)')
    parser.add_argument('--input', type=str,
                       help='ì‹¤ì œ ë°ì´í„° íŒŒì¼ ê²½ë¡œ (source=real ì‹œ í•„ìˆ˜)')
    parser.add_argument('--output-dir', type=str, default='./reports',
                       help='ë¦¬í¬íŠ¸ ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: ./reports)')
    parser.add_argument('--sample', type=int, default=5,
                       help='Markdownì— í¬í•¨í•  ìƒ˜í”Œ ë ˆì½”ë“œ ìˆ˜ (ê¸°ë³¸: 5)')
    parser.add_argument('--run-id', type=str,
                       help='ì‹¤í–‰ ID (ì—†ìœ¼ë©´ timestamp ìë™ ìƒì„±, íŒŒì¼ëª…ì— í¬í•¨)')
    parser.add_argument('--count', type=int, default=20,
                       help='Mock ëª¨ë“œ ìƒì„± ë ˆì½”ë“œ ìˆ˜ (ê¸°ë³¸: 20)')
    
    args = parser.parse_args()
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(args.output_dir, exist_ok=True)
    
    # ë°ì´í„° ë¡œë“œ
    if args.source == 'mock':
        print(f"ğŸ”§ Mock ë°ì´í„° ìƒì„± ì¤‘ ({args.count}ê±´)...")
        records = generate_mock_data(args.count)
        print(f"âœ… Mock ë°ì´í„° {len(records)}ê±´ ìƒì„± ì™„ë£Œ")
    else:
        if not args.input:
            print("âŒ ì˜¤ë¥˜: --source real ì‚¬ìš© ì‹œ --input íŒŒì¼ ê²½ë¡œê°€ í•„ìš”í•©ë‹ˆë‹¤")
            sys.exit(1)
        
        print(f"ğŸ“‚ íŒŒì¼ ë¡œë“œ ì¤‘: {args.input}")
        try:
            with open(args.input, 'r', encoding='utf-8') as f:
                records = json.load(f)
            print(f"âœ… {len(records)}ê±´ ë¡œë“œ ì™„ë£Œ")
        except FileNotFoundError:
            print(f"âŒ ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.input}")
            sys.exit(1)
        except json.JSONDecodeError:
            print(f"âŒ ì˜¤ë¥˜: JSON íŒŒì‹± ì‹¤íŒ¨: {args.input}")
            sys.exit(1)
    
    # í’ˆì§ˆ ê²€ì¦
    checker = DataQualityChecker(records)
    results = checker.check_all()
    
    # ë¦¬í¬íŠ¸ ìƒì„± (run-id ê¸°ë°˜ íŒŒì¼ëª…)
    run_id = args.run_id if args.run_id else datetime.now().strftime('%Y%m%d_%H%M%S')
    json_path = os.path.join(args.output_dir, f'data_quality_report_{args.source}_{run_id}.json')
    md_path = os.path.join(args.output_dir, f'data_quality_report_{args.source}_{run_id}.md')
    
    generate_json_report(results, json_path)
    generate_markdown_report(results, md_path, records[:args.sample] if args.sample > 0 else None)
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*60)
    print(f"ğŸ“Š ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì™„ë£Œ")
    print("="*60)
    print(f"ì´ ë ˆì½”ë“œ: {results['total_records']}ê±´")
    print(f"ìœ íš¨ ë ˆì½”ë“œ: {results['valid_records']}ê±´")
    print(f"ìµœì¢… íŒì •: {results['judgment']} ({results['pass_criteria_met']})")
    print(f"ì™„ì „ì„± ì ìˆ˜: {results['summary']['completeness_score']:.2f}/100")
    print(f"íŒŒì‹± ì ìˆ˜: {results['summary']['parsing_score']:.2f}/100")
    print("="*60)
    print(f"\nâœ… ë¦¬í¬íŠ¸ íŒŒì¼:")
    print(f"  - JSON: {json_path}")
    print(f"  - Markdown: {md_path}")
    print("\nğŸ’¡ Markdown ë¦¬í¬íŠ¸ë¥¼ í™•ì¸í•˜ì—¬ ìƒì„¸ ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.\n")


if __name__ == '__main__':
    main()
